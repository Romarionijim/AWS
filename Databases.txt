 Relational databases:
 structured tables columns relation between DB's
 SQL language to perform queries SQL => Relational

 noSQL
 no relational DB
 flexible schemas for building modern application
 benefits:
 flexibility: easy to evolve data model
 scalability: designed to scale out by using distributed clusters
 high performance: optimized for a specific data model
 high functional: types optimized for the data model

 examples: key-value databases, document, graph in memory (redis),search databases

 noSQL data example => JSON
 JSON is a common form of data that fits into noSQL model
 data can be nested
 fields can change over time
 support for new types, arrays and etc

 databases and shared responsibility on AWS:
 AWS:
 offers use to manage different databases for us
 benefits:
 quick provisioning, high availability, vertical and horizontal scaling easlity
 automated backup and restore databases, operations and upgrades
 operating system patching is handled by AWS
 monitoring alerting

 note: many databases technologies could be run on EC2, but you must handle yourself the resiliency , backup, patching, high availability,
 fault tolerance, scaling and etc...


 AWS RDS overview => relational database service => SQL
 tis allows you to create databases in the cloud that are managed by AWS
 postgres, mySQL, mariaDB, oracle, microsoft SQL Server, Aurora ( AWS proprietary database)

 advantage over using RDS vs deploying DB on EC2
 * RDS is a managed service
    automated provisioning, OS patching
    continuous backup and restore to a specific timestamp
    monitoring dashboards
    read replicas for improved read performance
    multi AZ setup for disaster recovery
    maintenance windows for upgrades
    scaling capability vertical and horizontal
    storage backed by EBS

 ** the only thing that we CANNOT do is SSH into the RDS DB instance.

 RDS solution architecture

 * elastic load balancer connected to EC2 instances that has auto scaling and balances the load of the backend app
 and the last layer that is the relational database that read and writes data to the EC2 instances

 Amazon Aurora:
 it is a DB technology created by AWS, it is not opensource
 it works the same way as RDS
 we have our EC2 instances connecting directly into Amazon Aurora
Aurora supports two kinds of database technologies
* postgresQL
* mySQL
Aurora is AWS cloud optimized and claims 5X performance improvements over mySQL on RDS, over 3x performance of postgres on RDS.
Aurora storage automatically grows in increments of 10GB up to 128TB
Aurora costs more than RDS 20% more but is more efficient.
not in the free tier but RDS is.
RDS and Aurora are going to be the two ways for you to create relational databases on AWS.
they are both managed and Aurora is going to be more cloud native whereas RDS is going to be running the technologies
directly is a managed service.

RDS deployment options:
* read replicas => reads from main RDS db
you can scale the read workload of your DB meaning that there going to be replicas of you RDS db that are going to be created.
this is going to allow our application to read from these replicas also.
you can create up to 15 read replicas
writing data is only done to the main database.

* multi AZ:
failover => in case of AZ outage (high availability)
so your application is still going to read and write from the same main RDS database but we are going to setup
a replication cross AZ in another different AZ and this is going to be a failover database
in case of the main RDS database crashes then RDS will trigger a failover and your applciation will failover to database in a
different AZ - so in this case data is only read and written to the main DB, the failover DB is passive,
it is not accessible until there is an issue with the main DB
you can only have one other AZ as a failover AZ

* multi region:
for read replicas but this time instead of being in the same region they are across different regions
for example we have the main DB in eu-west-1 and we create a read replica in us-east-2
applications in us-east-2 can read locally from this read replica
but anytime this application needs to write data => it writes to the main DB in eu-west-1 (Writing happens across region)

why multi region type deployment?
disaster recovery in case of region issue
local performance - our application in different regions get better performance because they read from a local database
so they have less latency
take account the replication cost with a network transfers of data between regions.

Amazon ElastiCache: type of DB
the same way RDS is to get managed relational databases
elasticache is to get managed redis or memcached
these caches are going to be in memory databases with high performance, low latency
helps reduce load off databases for read intensive workloads\
managed by AWS.

solution architicture for using elasicashe:
elastic load balancer will go to your EC2 instances - they will be reading and writing data from your amazon RDS DB, which is slow
and then if possible there will be caching some values into an amazon elasticache database and this will be very fast because its in memory
and there will be pressure taking off the main RDS database (cache the SQL queries) which will be easily accessible and relive
pressure from the main DB

DynamoDB:
fully managed high available with replication across 3 AZ.
it is noSQL databse.
flagship products of AWS
scales to massive workloads, and it is a "serverless" DB, no provisioning needed,
scales to million of requests per seconds, trillions of rows and hundreds of TB of storage
fast and consistent in performance
single digit millisecond latency - low latency retrieval
for the exam => serverless and low latency => DynamoDB
integrated with IAM for security, authorization and administration
low cost and auto-scaling capabilities
standard and infrequent access IA table class

type of data that get into dynamo DB:
key value DB

dynamo DB accelerator - DAX
a fully managed in memory cache for dynamo DB
10x performance improvment - single digit latency to microsecond latency - when accessing dynamoDB tables
secure highly scalable and highly available
DAX is only used for and is integrated with DynamoDB while elasticache can be used for other databases

DynamoDB global tables:
make a dynamodb table accessible with low latency in multiple regions

lets say we have the global table where we read and write the data in us-east-1
then we create a replica for this global table in eu-west-3
so we can create a global table in eu-west-3 - a two way replication between these tables
users who are close to the paris region in eu-west-3 can access the global table with low latency in paris
users can read and write to the table in any specific region - there will be just replication between these two.
write to any region and it will be actively be replicated into other regions

redshift overview:
it is based on postgreSQL but it is not used for online transaction processing. OLTP
instead it is OLAP - online analytical processing (analytics and data warehousing)
load data once every hour and not every second
10x better performance than any other data warehouse, scale to PBs of data
column storage of data instead of row based
massivley parallel query execution, highly available
pay as you go based on the instances provisioned
has an SQL intefrace for performin queries
it is integrated with BI
compute on data sets and analytics

EMR overview:
elastic mapReduce - it is not a DB - it helps for creating a hadoop cluster (Big Data) to analyze and process vast amount of data
hadoop is an open source technology that allows multiple servers that work in a cluster to analyze the data together
the clusters can be made of hundreds of EC2 instances that will be collaborating together to analyze your data
supports apache spark, Hbase, presto, flink..
what is EMR? it takes care of all provisioning and configuration of all these EC2 instances and configuring them so that they
work together and can analyze together data from a big data prespective
it has auto scaling and integrated with spot instances
use cases => data processing, machine learning, web indexing, big data

Athena overview:
is a serverless query service to perform analytics against S3 objects
use standard SQL language to query the files, you dont need to load them, they just need to be in s3 and Athena
will do the rest
supports files in the following formats: CSV, JSON, ORC, Avro and parquet (presto)
how it works? users upload data to S3 - Athena is to query and analyze the data
you could also have reporting on top of athena which is amazon quicksight
pricing: 5$ per TB of data scanned
use cases: BI / analytics / reporting, analyze && query VPC flow logs, ELB logs, cloudtrail trails and etc..
for the exam => analyze data in S3 using serverless SQL, use Athena.

Amazon quicksight:
serverless machine learning-powered intelligence service to create interactive dashboards
exam => allows you to create dashboards for your databases
fast automatically scalable, embeddable with per session pricing.
use cases:
    buisness analytics
    building visualizations
    perform ad-hoc analysis
    get buisness insights using data
    integrated with RDS Aurora, Athena, redshift, s3 and more..

DoucmentDB:
same way as Aurora - an AWS implementation/ cloud native version of postgres / mysql
DocumentDB is the same for MongoDB (nonSQL DB)
its based on top of the mongoDB technology - compatable with mongoDB
mongoDB is used to store, query and index JSON data
similar to deployment concepts as Aurora
fully managed, highly available with replication across 3 AZ
documentDB storage automatically grows in increments of 10GB up to 64 TB.

Automatically scales to workloads with millions of requests per seconds.
for the exam, mongo DB => think documentDB
noSQL DB think => documentDB and dynamoDB

neptune overview:
fully managed graph DB
like a social network
is a great choice of DB for graph data sets

highly available across 3 AZ up to 15 read replicas

build and run applications working highly connected datasets
can store up to billions of relations and query the graph with milliseconds latency
highly available with replications accross multiple AZ's
great for knowledge graphs, fraud detection, recommendation engines, social networking
for the exam =|> graph => think neptune

Amazon QLDB:
quantum ledgar database
a ledger is a book recording finincial transactions
fully managed DB and serverless, high  available, replication across 3 AZ
used to review history of all the changes made to your application overtime
immutable system: no entry can be removed or modified, cryptographically verofiable
2-3X better performance than common ledger blockchain frameworks, manipulate data using SQL
there is no concept of decentrailization
for the exam => financial transactions and ledger, immutable journal or cryptography veriablegit => QLDB

Amazon Managed Blockchain:
blockchain makes it possible to build application where multiple parites can execute transactions without the need
for a trusted, central authority.
for the exam => anything related to blockchains or hyperledger or ethereum => think Amazon managed blockchain
which also a decentralized blockchain

glue overview:
is a managed extract, transform and load service ETL.
what is all we need to know for the exam
ETL is useful to prepare and transform data for analytics.
fully serverless service

DMS overview:
database migration service => to migrate data from one DB to another
quick and secure databse migration to AWS, resilient, self healing
supports migrating same db technology such as oracle to oracle
or differnet such as aurora to ms sql server.
for the exam => migration of a databse => DMS.